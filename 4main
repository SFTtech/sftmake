#!/usr/bin/env python

import threading
import multiprocessing
import os.path
import re
import base64
import concurrent.futures
import subprocess
import shlex
import time
import random

class vartest():
	def __init__(self, arg):
		self.l = arg
	def get(self, a = ""):
		return self.l

try:
	relpath("^/a")
except NameError:
	print("redefining relpath() as stub")
	def relpath(path):
		'''stub for testing'''
		return path

try:
	generate_oname("gschicht")
except NameError:
	print("redefining generate_oname() as stub")
	def generate_oname(name):
		encoded = base64.b64encode(bytearray(name, 'utf-8'))
		return encoded.decode('utf-8')


#test purpose only
variables = {}
variables["c"] = vartest("gcc")
variables["build"] = vartest(["^/test", "^/liblol.so"])
variables["cflags"] = vartest("-O8 -flto=4")
variables["use"] = vartest(["^/gschicht.c", "^/asdf.c", "^/lolfolder/file.c"])
variables["objdir"] = vartest("^/.objdir")
variables["depends"] = vartest(['^/asdf.h','^/lol.h'])
variables["autodepends"] = vartest("MD")
variables["prebuild"] = vartest("")
variables["postbuild"] = vartest("")
variables["loglevel"] = vartest("2")
variables["ldflags"] = vartest("-lsft")


def get_thread_count():
	try:
		return multiprocessing.cpu_count()
	except NotImplementedError: # may happen under !POSIX
		fallback = 1
		sys.stderr.write('warning: cpu number detection failed, fallback to ' + fallback + '\n')
		return fallback;


class BuildJob:
	def __init__(self):
		self.thread = threading.Thread(target=self.run)

	def run(self):
		pass


class JobStatus:
	def __init__(self, job):
		self.running = False
		self.exitstate = 0
		self.job = job

	def status(self):
		self.job.thread.join()
		return self.exitstate


class JobManager:
	"""thread manager for invoking the compilers"""
	def __init__(self, max_workers=get_thread_count()):
		self.current_jobs = []
		self.pending_jobs = []
		self.max_workers = max_workers

	def job_finished(self, job):
		"""one executing job was finished"""

		#TODO: check for exit status etc.
		if(len(self.current_jobs) < self.max_workers):

			if(len(self.pending_jobs) > 0):
				to_execute = self.pending_jobs.pop(0)
				#launch the next pending job

	def submit(self, job):
		"""insert a function in the execution queue"""
		if(not isinstance(job, BuildJob)):
			raise Exception("only BuildJobs can be submitted")

		newone = JobStatus(job) #the new job gets it's own status wrapper
		self.pending_jobs.append(newone)
		
		pass


class BuildOrder:
	'''A build order contains all targets that must be built'''
	def __init__(self):
		self.targets = []
		self.max_jobs = get_thread_count()
	def add_target(self, target):
		self.targets.append(target)
	def job_count(self, n = get_thread_count()):
		self.max_jobs = n

	def __str__(self):
		out = "\n\n%%%%%%%%%%%%%%%%%\n BUILD ORDER"
		for t in self.targets:
			out += str(t)
		out += "\n%%%%%%%%%%%%%%%%%\n"
		return out

class BuildTarget:
	'''A build target has a list of all sources that will be linked in the target'''
	def __init__(self, tname):
		self.files = []
		self.name = tname
		self.t_run = ""
		self.prebuild = ""
		self.postbuild = ""

	def add_file(self, cfile):
		self.files.append(cfile)

	def set_t_run(self, t_run):
		self.t_run = t_run

	def __str__(self):
		out = "\n>>>>>>>>>>>>>>>>>>>>>>>>>\ntarget file: " + relpath(self.name)
		out += " -> \n"
		n = 0
		for f in self.files:
			out += "\n-- file " + str(n) + ":" + str(f)
			n += 1
		out += "\t c_invokation: " + self.t_run + "\n>>>>>>>>>>>>>>>>>>>>>>>>>\n"
		return out


class BuildFile:
	'''A build file object only stores the filename and its (header) dependencies'''
	def __init__(self, fname):
		self.name = fname
		self.depends = []
		self.needs_build = False
		self.c_run = ""
		self.prebuild = ""
		self.postbuild = ""
	
	def set_c_run(self, c_run):
		self.c_run = c_run

	def set_enc_name(self, e):
		self.enc_name = e

	def add_dependency(self, dfile):
		if(type(dfile) == list):
			self.depends += dfile
		else:
			self.depends.append(dfile)

	def __repr__(self):
		return relpath(self.name)

	def __str__(self):
		out = "\n===========\nsource file: " + relpath(self.name) + " -> \n"
		n = 0
		for d in self.depends:
			out += "\tdep " + str(n) + ":\t" + relpath(d) + "\n"
			n += 1

		out += "\tc_invokation: " + self.c_run + "\n===========\n"
		return out



def build_worker(manager,ofile):
	'''this method compiles a single object.'''

	o_name = ofile.enc_name + ".o"
	c_name = relpath(ofile.name)

	if(os.path.isfile(o_name)):
		if (os.path.getmtime(o_name) < os.path.gettime(c_name)):
			ofile.needs_build = True
		else:
			ofile.needs_build = False

	else: # .o does not exist
		ofile.needs_build = True


	if(not ofile.needs_build):
		for fl in ofile.depends:
			try:
				# check for modification times
				print("checking mtime of -> " + fl)
				if(os.path.getmtime(fl) > os.path.getmtime(o_name)):
					ofile.needs_build = True
					break

			except OSError as e:
				print(str(e) + " -> Ignoring for now.")

	if(ofile.needs_build):

		ret = 0

		if(ofile.prebuild):
			print("prebuild for " + ofile + " '" + ofile.prebuild + "'")
			#ret = subprocess.call(shlex.split(ofile.prebuild), shell=False)
			pass

		if(ret != 0):
			failat = "prebuild for"
			pass
		else:
			print("== building -> " + c_name)
			#ret = subprocess.call(shlex.split(ofile.c_run), shell=False)
			time.sleep(1)
			print("== done building -> " + c_name)

		#TODO: don't forget to remove...
		if(manager.error == 0): #generate ONE random build fail
			ret = round(random.random())
		else:
			ret = 0

		if(ret != 0):
			failat = "compiling"
		else:
			if(ofile.postbuild):
				print("postbuild for " + ofile + " '" + ofile.postbuild + "'")
				#ret = subprocess.call(shlex.split(ofile.postbuild), shell=False)
				pass
			if(ret != 0):
				failat = "postbuild for"

		if(ret > 0):
			fail = True
		else:
			fail = False

		if fail:
			print("\n======= Fail at "+ failat +" " + repr(ofile) + " =========")
			manager.error = ret
			print("Error when building "+ c_name )
			return 1
		else:
			return 0

	#doesn't need build
	else:
		print("skipping " + c_name)


class Builder:
	def __init__(self, conf):
		self.conf = conf
		self.error = 0

	def build(self, order):
		'''process a build_order'''
		if(type(order) != BuildOrder):
			raise Exception("Builder: the build() function needs a BuildOrder")

		self.e = concurrent.futures.ThreadPoolExecutor(max_workers=order.max_jobs)

		targetsstr = "'"
		for t in order.targets:
			targetsstr += t.name + " "
		targetsstr += "'"
		print("\n\norder contains " + targetsstr)

		for target in order.targets:
			rtarget = relpath(target.name)
			print("\n\n===== Building target " + rtarget)

			worker_results = []
			for ofile in target.files:
				if(self.error == 0):
					print("state:" + str(self.error))

					#submit a new job to queue:
					f = self.e.submit(build_worker, self, ofile)

					worker_results.append(f)
				else:
					print("[ Job queue canceled ]")
					break

				#b = threading.Thread(target=build_worker, args=[self, ofile])

			for res in worker_results:
				print("ret => " + str(res.result()) + " -> " + relpath(ofile.name))
			if(self.error > 0):
				self.e.shutdown(wait=True)
				break
			else:
				print("\n=== Linking target " + rtarget)
				print(" => " + target.t_run)
				time.sleep(2)

		#after all targets:
		if(self.error == 0):
			print("sftmake shutting down...")
			self.e.shutdown(wait=True)
		else:
			print("errors caused sftmake to exit")




	def prepare(self):
		'''generate a build order for later processing'''
		order = BuildOrder()
		for target in self.conf["build"].get():
			order_target = BuildTarget(target)

			for source in self.conf["use"].get(target):
				order_file = BuildFile(source)

				c_run = ""

				c_run += self.conf["c"].get(source)		#compiler
				c_run += " " + self.conf["cflags"].get(source)	#compiler flags
				c_run += " -c " + relpath(source)		#sourcefile name

				# encode the compiler flags etc
				objdir = self.conf["objdir"].get(source)
				enc_name = relpath(objdir) + "/" + relpath(source) + "-" + generate_oname(c_run)	#TODO: This line contains 99% bugs
				order_file.set_enc_name(enc_name)

				o_name = enc_name + ".o"
				c_run += " -o " + o_name	 		#output object file name generation

				# add known (by config) dependency files
				order_file.add_dependency(self.conf["depends"].get(source))
				
				#add sourcefile path itself to depends
				ad = self.conf["autodepends"].get(source)

				if(ad == "MD"):
					mdfile = enc_name + ".d"

					if(os.path.isfile(mdfile)):
						order_file.add_dependency(parse_dfile(mdfile))

					else:
						order_target.add_file(order_file)

					c_run += " -MD"  # generate c headers dependency file

				elif(ad == "no"):
					#kp evtl auch iwas
					pass
				else:
					#let's ignore an unknown autodetection mode
					print(source + ": unknow autodetection mode: " + ad);

				order_file.loglevel = self.conf["loglevel"].get(source)

				s_prb = self.conf["prebuild"].get(source)
				if(len(s_prb) > 0):
					order_file.prebuild = s_prb

				s_pob = self.conf["postbuild"].get(source)
				if(len(s_pob) > 0):
					order_file.postbuild = s_pub

				# compiler invocation complete -> add it to the source file build order
				order_file.set_c_run(c_run)


				order_target.add_file(order_file)
				#print(str(order_file))

			#=> continuation for each target
			#compiler_invocation = \{prebuild}; \{c} \{cflags} \{lflags} \{libs} [type-specific flags] \{objects} -o \(oname); \{postbuild}

			t_run = self.conf["c"].get(target)		#compiler
			t_run += " " + self.conf["cflags"].get(target)	#compiler flags
			t_run += " " + self.conf["ldflags"].get(target)	#link flags
			t_run += " -o " + relpath(target)		#target output name

			#append all object files for linkage
			for ofile in order_target.files:
				t_run += " " + relpath(ofile.enc_name + ".o")

			t_prb = self.conf["prebuild"].get(target)
			if(len(s_prb) > 0):
				order_target.prebuild = t_prb

			s_pob = self.conf["postbuild"].get(target)
			if(len(s_pob) > 0):
				order_target.postbuild = t_pob

			order_target.set_t_run(t_run)

			#include current target to the build order
			order.add_target(order_target)

		#direct function level
		print(str(order))
		return order



def parse_dfile(filename):
	'''parse a .dfile and return a list of dependency headers'''
	try:
		with open(filename, 'r') as f:
			content = f.readlines() #list of line, including a trailing \\n (sic)
			content = [ clean_dfile_line(l) for l in content ]
			dependencies = []
			for part in content: # concat all lists
				dependencies += part

			return dependencies
	except IOError as e:
		return [];

def clean_dfile_line(line):
	'''converts a .dfile line to a list of header dependencies'''
	hmatch = re.compile(r"[-\w/\.]+\.(h|hpp)") #matches a single header file
	parts = re.split(r"\s+", line)

	#return all matching header files as list
	return list(filter(lambda part: hmatch.match(part), parts))
#	return [ part for part in parts if hmatch.match(part) ]




def main():
	print("fak u dolan")
	#print(str(variables["build"].get()))
	builder = Builder(variables)
	order = builder.prepare()
	builder.build(order)


if __name__ == "__main__":
	main()
